{"hiddenService":"35oktenzdrt2v4o5.onion","webDetected":true,"sshDetected":false,"ricochetDetected":false,"ircDetected":false,"ftpDetected":false,"smtpDetected":false,"bitcoinDetected":false,"mongodbDetected":false,"vncDetected":false,"xmppDetected":false,"serverPoweredBy":"","serverVersion":"Apache/2.4.10 (Raspbian)","foundApacheModStatus":false,"relatedOnionServices":null,"relatedOnionDomains":null,"linkedSites":["www.tandfonline.com","ahmia.fi","onion.city","wordpress.org","wordpress.com","www.gnu.org","underscores.me","meyerweb.com","necolas.github.com","www.blueprintcss.org","clagnut.com","www.paulirish.com","caniuse.com","gmpg.org","fonts.googleapis.com","api.w.org","ridt.co"],"internalPages":["35oktenzdrt2v4o5.onion",""],"ipAddresses":null,"openDirectories":null,"exifImages":null,"interestingFiles":null,"pageReferencedDirectories":["35oktenzdrt2v4o5.onion","35oktenzdrt2v4o5.onion/feed","35oktenzdrt2v4o5.onion/comments/feed","35oktenzdrt2v4o5.onion","35oktenzdrt2v4o5.onion","35oktenzdrt2v4o5.onion","35oktenzdrt2v4o5.onion/about","35oktenzdrt2v4o5.onion/cryptopolitik","35oktenzdrt2v4o5.onion/cryptopolitik","35oktenzdrt2v4o5.onion/author/ridt","35oktenzdrt2v4o5.onion/cryptopolitik","35oktenzdrt2v4o5.onion/methodology","35oktenzdrt2v4o5.onion/methodology","35oktenzdrt2v4o5.onion/author/ridt","35oktenzdrt2v4o5.onion/methodology","35oktenzdrt2v4o5.onion/cryptopolitik","35oktenzdrt2v4o5.onion/methodology","35oktenzdrt2v4o5.onion/about"],"pgpKeys":null,"hashes":["ce6db9da4a5baf3805c4c6bd8adb38e7c66cdf53"],"snapshot":"\u003c!DOCTYPE html\u003e\n\u003chtml lang=\"en-US\"\u003e\n\u003chead\u003e\n\u003cmeta charset=\"UTF-8\" /\u003e\n\u003cmeta name=\"viewport\" content=\"width=device-width\" /\u003e\n\u003ctitle\u003eCryptopolitik\u003c/title\u003e\n\u003clink rel=\"profile\" href=\"http://gmpg.org/xfn/11\" /\u003e\n\u003clink rel=\"pingback\" href=\"http://35oktenzdrt2v4o5.onion/xmlrpc.php\" /\u003e\n\n\u003clink rel=\"alternate\" type=\"application/rss+xml\" title=\"Cryptopolitik \u0026raquo; Feed\" href=\"http://35oktenzdrt2v4o5.onion/feed/\" /\u003e\n\u003clink rel=\"alternate\" type=\"application/rss+xml\" title=\"Cryptopolitik \u0026raquo; Comments Feed\" href=\"http://35oktenzdrt2v4o5.onion/comments/feed/\" /\u003e\n\u003cstyle type=\"text/css\"\u003e\nimg.wp-smiley,\nimg.emoji {\n\tdisplay: inline !important;\n\tborder: none !important;\n\tbox-shadow: none !important;\n\theight: 1em !important;\n\twidth: 1em !important;\n\tmargin: 0 .07em !important;\n\tvertical-align: -0.1em !important;\n\tbackground: none !important;\n\tpadding: 0 !important;\n}\n\u003c/style\u003e\n\u003clink rel='stylesheet' id='syntax-style-css'  href='http://35oktenzdrt2v4o5.onion/wp-content/themes/syntax/style.css?ver=4.4.1' type='text/css' media='all' /\u003e\n\u003clink rel='stylesheet' id='syntax-merriweather-css'  href='http://fonts.googleapis.com/css?family=Merriweather%3A400%2C300italic%2C300%2C400italic%2C700%2C700italic\u0026#038;subset=latin%2Clatin-ext\u0026#038;ver=4.4.1' type='text/css' media='all' /\u003e\n\u003cscript type='text/javascript' src='http://35oktenzdrt2v4o5.onion/wp-includes/js/jquery/jquery.js?ver=1.11.3'\u003e\u003c/script\u003e\n\u003cscript type='text/javascript' src='http://35oktenzdrt2v4o5.onion/wp-includes/js/jquery/jquery-migrate.min.js?ver=1.2.1'\u003e\u003c/script\u003e\n\u003clink rel='https://api.w.org/' href='http://35oktenzdrt2v4o5.onion/wp-json/' /\u003e\n\u003clink rel=\"EditURI\" type=\"application/rsd+xml\" title=\"RSD\" href=\"http://35oktenzdrt2v4o5.onion/xmlrpc.php?rsd\" /\u003e\n\u003cmeta name=\"generator\" content=\"WordPress 4.4.1\" /\u003e\n\u003c/head\u003e\n\n\u003cbody class=\"home blog\"\u003e\n\u003cdiv id=\"page\" class=\"hfeed site\"\u003e\n\t\t\u003cheader id=\"masthead\" class=\"site-header\" role=\"banner\"\u003e\n\t\t\t\t\u003cdiv class=\"site-header-wrapper clear\"\u003e\n\t\t\t\u003cdiv class=\"site-branding\"\u003e\n\t\t\t\t\u003ch1 class=\"site-title\"\u003e\u003ca href=\"http://35oktenzdrt2v4o5.onion/\" title=\"Cryptopolitik\" rel=\"home\"\u003eCryptopolitik\u003c/a\u003e\u003c/h1\u003e\n\t\t\t\t\u003ch2 class=\"site-description\"\u003e\u003c/h2\u003e\n\t\t\t\u003c/div\u003e\n\t\t\t\t\t\u003c/div\u003e\n\t\u003c/header\u003e\u003c!-- #masthead --\u003e\n\t\u003cdiv id=\"main\" class=\"site-main\"\u003e\n\t\t\u003ch1 id=\"toggle-nav\" class=\"menu-toggle\"\u003e\u003cspan class=\"screen-reader-text\"\u003eMenu\u003c/span\u003e\u003c/h1\u003e\n\t\t\u003cnav id=\"site-navigation\" class=\"navigation-main\" role=\"navigation\"\u003e\n\t\t\t\u003cdiv class=\"screen-reader-text skip-link\"\u003e\u003ca href=\"#content\" title=\"Skip to content\"\u003eSkip to content\u003c/a\u003e\u003c/div\u003e\n\t\t\t\u003cdiv class=\"menu\"\u003e\u003cul\u003e\u003cli class=\"current_page_item\"\u003e\u003ca href=\"http://35oktenzdrt2v4o5.onion/\"\u003eHome\u003c/a\u003e\u003c/li\u003e\u003cli class=\"page_item page-item-8\"\u003e\u003ca href=\"http://35oktenzdrt2v4o5.onion/about/\"\u003eThe Authors\u003c/a\u003e\u003c/li\u003e\u003c/ul\u003e\u003c/div\u003e\n\t\t\u003c/nav\u003e\u003c!-- #site-navigation --\u003e\n\n\t\u003cdiv id=\"primary\" class=\"content-area\"\u003e\n\t\t\u003cdiv id=\"content\" class=\"site-content\" role=\"main\"\u003e\n\n\t\t\n\t\t\t\t\t\t\n\t\t\t\t\u003carticle id=\"post-16\" class=\"no-thumbnail post-16 post type-post status-publish format-standard hentry category-uncategorized\"\u003e\n\t\u003cheader class=\"entry-header\"\u003e\n\t\t\t\t\u003ch1 class=\"entry-title\"\u003e\u003ca href=\"http://35oktenzdrt2v4o5.onion/cryptopolitik/\" rel=\"bookmark\"\u003eCryptopolitik and the Darknet\u003c/a\u003e\u003c/h1\u003e\t\u003c/header\u003e\u003c!-- .entry-header --\u003e\n\n\t\t\u003cdiv class=\"entry-content\"\u003e\n\t\t\u003cp\u003e\u003ca href=\"http://www.tandfonline.com/doi/full/10.1080/00396338.2016.1142085\" target=\"_blank\"\u003eA research article by Daniel Moore and Thomas Rid, out in \u003cem\u003eSurvival\u003c/em\u003e, Feb/Mar 2016\u003c/a\u003e.\u003c/p\u003e\n\u003cp style=\"padding-left: 20px;\"\u003e\u003cimg class=\"alignleft\" src=\"https://ridt.co/i/survival.png\" alt=\"\" width=\"148\" height=\"197\" /\u003eThe Crypto Wars are back, with Silicon Valley companies and privacy activists pitched against governments and law enforcement in a fierce ideological standoff — again. In the 1990s, the rift was often abstract and many arguments theoretical; in the mid-2010s, crytpo-politics have a life-or-death urgency and often traumatising practical consequences. This means we can now put highbrow questions to an empirical test. Is there a difference between liberal and illiberal cryptographic architectures?\u003c/p\u003e\n\u003cp style=\"padding-left: 20px;\"\u003eThis question isn’t a normative one any longer; it is now an empirical one. To reveal actual use-patterns, we sighted a significant part of the “darknet” — of Tor Hidden Services. Informed by hard facts and history, we suggest a way to draw a line between good and bad encryption. Drawing this line is inevitable, not our choice: math and algorithms may be pure and innocent; but technical implementations and protocols embody moral values and political choices. It is time to transcend the hackneyed views at the ideological fringes on both sides. A sober, poised, and analytical \u003ci\u003eRealpolitik\u003c/i\u003e approach to encryption is urgently needed.\u003c/p\u003e\n\t\t\t\u003c/div\u003e\u003c!-- .entry-content --\u003e\n\t\n\t\u003cfooter class=\"entry-meta\"\u003e\n\t\t\t\t\t\u003cspan class=\"post-date\"\u003e\u003ca href=\"http://35oktenzdrt2v4o5.onion/cryptopolitik/\" title=\"8:57 pm\" rel=\"bookmark\"\u003e\u003ctime class=\"entry-date\" datetime=\"2016-01-18T20:57:26+00:00\"\u003eJanuary 18, 2016\u003c/time\u003e\u003c/a\u003e\u003c/span\u003e\u003cspan class=\"byline\"\u003e\u003cspan class=\"author vcard\"\u003e\u003ca class=\"url fn n\" href=\"http://35oktenzdrt2v4o5.onion/author/ridt/\" title=\"View all posts by ridt\" rel=\"author\"\u003eridt\u003c/a\u003e\u003c/span\u003e\u003c/span\u003e\t\t\t\t\t\n\t\t\t\t\u003cspan class=\"comments-link\"\u003e\u003ca href=\"http://35oktenzdrt2v4o5.onion/cryptopolitik/#comments\"\u003e7 Comments\u003c/a\u003e\u003c/span\u003e\n\t\t\n\t\t\t\u003c/footer\u003e\u003c!-- .entry-meta --\u003e\n\u003c/article\u003e\u003c!-- #post-## --\u003e\n\n\t\t\t\n\t\t\t\t\u003carticle id=\"post-69\" class=\"no-thumbnail post-69 post type-post status-publish format-standard hentry category-uncategorized\"\u003e\n\t\u003cheader class=\"entry-header\"\u003e\n\t\t\t\t\u003ch1 class=\"entry-title\"\u003e\u003ca href=\"http://35oktenzdrt2v4o5.onion/methodology/\" rel=\"bookmark\"\u003eTechnical Annex: Indexing Tor Hidden Services\u003c/a\u003e\u003c/h1\u003e\t\u003c/header\u003e\u003c!-- .entry-header --\u003e\n\n\t\t\u003cdiv class=\"entry-content\"\u003e\n\t\t\u003cp\u003eBy D. Moore\u003c/p\u003e\n\u003cp\u003eFor Moore, D and T Rid, “Cryptopolitik and the Darknet,” \u003ci\u003eSurvival\u003c/i\u003e, Feb/March 2016\u003c/p\u003e\n\u003ch4\u003e\u003cb\u003eSummary\u003c/b\u003e\u003c/h4\u003e\n\u003cp\u003eThe Tor hidden services (henceforth, HS) classification process was performed in six steps:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eCompiled a bootstrap list of HS to be automatically crawled by extracting the HS list provided by onion.city and ahmia.fi.\u003c/li\u003e\n\u003cli\u003eRan custom Python-based crawling script utilizing a Tor SOCKS connection to harvest textual information from HTTP-based HS. Each HS was harvested for up to 100 pages. Links to additional HS were also extracted from the harvested materials. The script ran for a total of five weeks.\u003c/li\u003e\n\u003cli\u003eUsed random page sampling to construct diverse training corpus for the classification algorithm.\u003c/li\u003e\n\u003cli\u003eTrained and tested the algorithm, tweaked parameters, categories and feature extraction until results were consistently reliable (\u0026gt;95% precision and recall).\u003c/li\u003e\n\u003cli\u003eRan classification on document corpus, analyzed results.\u003c/li\u003e\n\u003cli\u003eManually tested classified pages to observe accuracy of classification.\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch4\u003e\u003cb\u003eData-Scraping Process\u003c/b\u003e\u003c/h4\u003e\n\u003cp\u003eThe initial seed list of HS was assembled by harvesting public .onion repositories. Two websites proved useful to the task – \u003ca href=\"http://ahmia.fi\"\u003ehttp://ahmia.fi\u003c/a\u003e and \u003ca href=\"http://onion.city\"\u003ehttp://onion.city\u003c/a\u003e, both of which allow connecting to .onion sites not through Tor (effectively insecurely bridging the gap between HS and the conventional internet).  The assembled list was especially diverse as the above sites do not filter sites, except  for outrageously illicit content (primarily child pornography). For example, ahmia.fi filters 58 out of 5286 hidden services as of January 19, 2016.\u003c/p\u003e\n\u003cp\u003eWe started out with constructing the crawler. The Tor crawler was a relatively simple script coded in Python. The design included a persistency mechanism to keep a detailed account of HS sites that were crawled, with results stored in a MongoDB instance. The requests themselves were piped into the Tor network through a combination of Privoxy and Tor SOCKS connections. HS which did not properly respond to connection attempts were retried during each iteration to alleviate temporary connectivity issues.\u003c/p\u003e\n\u003cp\u003eVarious extensions which were deemed as irrelevant to textual content were excluded from scanning. This included executables, archives and media formats (audio, video, images), as well as assorted miscellaneous formats (e.g. .bin).  These files and links were immediately discarded and did not count towards the per-HS crawl limitation.\u003c/p\u003e\n\u003cp\u003eThe crawling process took five weeks, during which it ran continuously. We ended the crawling when the rate of new pages generated was continuously near-zero. Websites which \u0026#8211; at the end of the process \u0026#8211; did not respond to requests were auto-assigned the ‘\u003ci\u003eNone’\u003c/i\u003e category. This proved to be very common: over 1,000 websites were entirely non-responsive.\u003c/p\u003e\n\u003cp\u003eThe webpages themselves were subjected to a sanitisation process designed to extract textual content. This process entailed stripping away HTML tags, invisible text (e.g. comments), embedded media, and Javascript. The extracted text was submitted to the \u003ci\u003elangid \u003c/i\u003ePython language classification library, the results of which were used to Google-Translate non-English content. Google Translate may often poorly translate entire sentences for reading by human eyes. But its output still yields acceptable translations on a word-by-word basis, which makes it suitable for automatic text classification.\u003c/p\u003e\n\u003cp\u003eThe normalized text was hashed and introduced into the MongoDB instance, if it was new. If we had already seen the hash before, a reference to it would be stored instead. This ensured that we would not be counting multiple classifications of the exact same page \u003ci\u003efor a given website.\u003c/i\u003e Content could certainly be copied between websites and still be counted.\u003c/p\u003e\n\u003ch4\u003e\u003cb\u003ePreparing the Classifier\u003c/b\u003e\u003c/h4\u003e\n\u003cp\u003eI searched for a best-fit algorithm that would yield distinct category classification without significant loss in accuracy or recall. This proved difficult as Tor darknet content was highly varied and often polluted with textual artifacts (textual elements irrelevant to the content). Naïve Bayes and K-Nearest Neighbours, two common classification algorithms, did not yield satisfactory results, but likely could have if tinkered with sufficiently. After several bouts of trial and error, I settled on the \u003ci\u003escikit-learn\u003c/i\u003e Python library’s implementation of multiclass Support Vector Machines (SVM).\u003c/p\u003e\n\u003cp\u003eSVM is a common text classification algorithm frequently used in text classification problems. To properly use it, the following requirements must be met:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eSelect and configure a \u003ci\u003efeature extractor\u003c/i\u003e. Features are the fundamental data-building blocks assessed by the algorithm. In text-classification problems, these are often words.\u003c/li\u003e\n\u003cli\u003eSelect categories. These must be sufficiently distinct and representative in order for classification to enjoy high precision/recall rates.\u003c/li\u003e\n\u003cli\u003eConstruct a training corpus comprised of sufficient samples per category. The training corpus is a collection of documents which have been pre-emptively identified as belonging to a given category.\u003c/li\u003e\n\u003cli\u003eTrain the classifier with the corpus and note the results. The classifier can create a training-testing split in the training corpus that allows it to assess its own accuracy. The two main parameters used to assess said accuracy are \u003ci\u003eprecision \u003c/i\u003eand \u003ci\u003erecall.\u003c/i\u003e\n\u003col\u003e\n\u003cli\u003e\u003ci\u003ePrecision\u003c/i\u003e – Out of the X documents assigned category Y, how many were in fact category Y?\u003c/li\u003e\n\u003cli\u003e\u003ci\u003eRecall\u003c/i\u003e – Out of the X documents that were in fact category Y, how many were assigned category Y?\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eI used a \u003ci\u003eTfidfVectorizer\u003c/i\u003e for the feature extractor, which essentially corresponded to my use of words as the primary data block. I experimented heavily with categories that would generate a reliable fit to the data. Initially, I attempted to categorize based on behaviour (criminal marketplaces, illicit wikis), but the results were inconsistent. The resulting taxonomy was a blend of behavioural (e.g. social) and topical (e.g. drugs) classifications, providing a decent fit for variations in Tor HS content. The vast majority of categories were thematic, as this resulted in more distinct terminology and textual patterns per category.\u003c/p\u003e\n\u003cp\u003eIn order to generate the training corpus I wrote a second script which randomly sampled the MongoDB instance and displayed the results. Pages were manually assigned categories by me, based on the predominant theme. A primary guiding principle was \u003ci\u003ebenefit of the doubt\u003c/i\u003e – if I couldn’t reliably determine the nature of a page, I would assign it the Other category. Other safeguards were in place to ensure variation in the training corpus, such as a low limit on the amount of pages I classified per HS. The resulting corpus was comprised of 634 documents.\u003c/p\u003e\n\u003cp\u003eInterestingly enough, the ‘None’ category was a distinct category which had documents assigned to its training corpus. This is because I included within this category placeholder pages such as blog templates and default Apache (HTTP server) responses. These were surprisingly more common than initially assumed, with more than 1,000 websites found with placeholder content. Based on this, it seems that many individuals choose to host HS within the Tor darknet but do not follow up on the actual generation of content.\u003c/p\u003e\n\u003cp\u003eThe training corpus was used to generate \u003cb\u003etwo classifiers:\u003c/b\u003e\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eA \u003ci\u003econtent classifier\u003c/i\u003e – based on the textual content of web pages.\u003c/li\u003e\n\u003cli\u003eA \u003ci\u003etitle classifier\u003c/i\u003e – based on the HTML titles extracted from each page. These were often indicative of the website’s content.\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch4\u003e\u003cb\u003eClassification\u003c/b\u003e\u003c/h4\u003e\n\u003cp\u003eThe classification logic worked as follows:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eThe two SVM classifiers were run on each document and categories assigned.\u003c/li\u003e\n\u003cli\u003eFor each website, I classified up to 100 web pages (with both classifiers), to ensure that ‘misrepresenting’ pages were not predominantly determining the website’s category. For example, if a website chiefly dedicates to arms trade had several pages on fraudulent money transfers, it could influence the overall classification of the site. But if the classifier analysed 100 pages and only 4 of these were dedicated to financial activity, the correct category would still prevail in the overall category assignment for the entire site.\u003c/li\u003e\n\u003cli\u003eIf a page had less than 50 words, it was assigned the ‘\u003ci\u003enone’ \u003c/i\u003ecategory.\u003c/li\u003e\n\u003cli\u003eAn aggregate classifier category determination was made \u003ci\u003eonly \u003c/i\u003eif over 50% of the pages were assigned to a single category.\u003c/li\u003e\n\u003cli\u003eAn overall website category determination was made \u003ci\u003eonly \u003c/i\u003eif both title and content classifiers agreed on the category.\u003c/li\u003e\n\u003cli\u003eIf both classifiers could not internally agree on a category, the script assigned the website the ‘Unknown/Unclear’ category.\u003c/li\u003e\n\u003cli\u003eIf each classifier could not agree on a category between them, the script flagged the website for manual review and category classification.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThe crawler collected 239,000 unique pages from 5,205 sites, out of which 50,000 were used for classification. Post-classification, I again randomly sampled 50 distinct websites from different categories to review their classification. Aside for two cases in which the \u003ci\u003esocial \u003c/i\u003ecategory was assigned to forums focused on exchanging information on the manufacturing of narcotics, the categories assigned were correct.\u003c/p\u003e\n\u003cp\u003eDetailed results are in our full article.\u003c/p\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\t\t\t\u003c/div\u003e\u003c!-- .entry-content --\u003e\n\t\n\t\u003cfooter class=\"entry-meta\"\u003e\n\t\t\t\t\t\u003cspan class=\"post-date\"\u003e\u003ca href=\"http://35oktenzdrt2v4o5.onion/methodology/\" title=\"8:56 pm\" rel=\"bookmark\"\u003e\u003ctime class=\"entry-date\" datetime=\"2016-01-18T20:56:31+00:00\"\u003eJanuary 18, 2016\u003c/time\u003e\u003c/a\u003e\u003c/span\u003e\u003cspan class=\"byline\"\u003e\u003cspan class=\"author vcard\"\u003e\u003ca class=\"url fn n\" href=\"http://35oktenzdrt2v4o5.onion/author/ridt/\" title=\"View all posts by ridt\" rel=\"author\"\u003eridt\u003c/a\u003e\u003c/span\u003e\u003c/span\u003e\t\t\t\t\t\n\t\t\t\t\u003cspan class=\"comments-link\"\u003e\u003ca href=\"http://35oktenzdrt2v4o5.onion/methodology/#comments\"\u003e3 Comments\u003c/a\u003e\u003c/span\u003e\n\t\t\n\t\t\t\u003c/footer\u003e\u003c!-- .entry-meta --\u003e\n\u003c/article\u003e\u003c!-- #post-## --\u003e\n\n\t\t\t\n\t\t\t\n\t\t\n\t\t\u003c/div\u003e\u003c!-- #content --\u003e\n\t\u003c/div\u003e\u003c!-- #primary --\u003e\n\n\t\u003cdiv id=\"secondary\" class=\"widget-area\" role=\"complementary\"\u003e\n\t\t\t\t\t\t\t\t\t\u003c/div\u003e\u003c!-- #secondary --\u003e\n\n\t\u003c/div\u003e\u003c!-- #main --\u003e\n\t\u003cfooter id=\"colophon\" class=\"site-footer\" role=\"contentinfo\"\u003e\n\t\t\t\t\t\u003cdiv class=\"secondary-navigation\"\u003e\n\t\t\t\t\u003cdiv class=\"menu-footer-container\"\u003e\u003cul id=\"menu-footer\" class=\"menu\"\u003e\u003cli id=\"menu-item-22\" class=\"menu-item menu-item-type-post_type menu-item-object-post menu-item-22\"\u003e\u003ca href=\"http://35oktenzdrt2v4o5.onion/cryptopolitik/\"\u003eCryptopolitik and the Darknet\u003c/a\u003e\u003c/li\u003e\n\u003cli id=\"menu-item-75\" class=\"menu-item menu-item-type-post_type menu-item-object-post menu-item-75\"\u003e\u003ca href=\"http://35oktenzdrt2v4o5.onion/methodology/\"\u003eTechnical Annex\u003c/a\u003e\u003c/li\u003e\n\u003cli id=\"menu-item-10\" class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-10\"\u003e\u003ca href=\"http://35oktenzdrt2v4o5.onion/about/\"\u003eThe Authors\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\u003c/div\u003e\t\t\t\u003c/div\u003e\n\t\t\t\t\u003cdiv class=\"site-info\"\u003e\n\t\t\t\t\t\t\u003ca href=\"http://wordpress.org/\" title=\"A Semantic Personal Publishing Platform\" rel=\"generator\"\u003eProudly powered by WordPress\u003c/a\u003e\n\t\t\t\u003cspan class=\"sep\"\u003e ~ \u003c/span\u003e\n\t\t\tTheme: Syntax by \u003ca href=\"https://wordpress.com/themes/\" rel=\"designer\"\u003eWordPress.com\u003c/a\u003e.\t\t\u003c/div\u003e\u003c!-- .site-info --\u003e\n\t\u003c/footer\u003e\u003c!-- #colophon --\u003e\n\u003c/div\u003e\u003c!-- #page --\u003e\n\n\u003cscript type='text/javascript' src='http://35oktenzdrt2v4o5.onion/wp-content/themes/syntax/js/siteheader.js?ver=20120206'\u003e\u003c/script\u003e\n\u003cscript type='text/javascript' src='http://35oktenzdrt2v4o5.onion/wp-content/themes/syntax/js/skip-link-focus-fix.js?ver=20130115'\u003e\u003c/script\u003e\n\u003cscript type='text/javascript' src='http://35oktenzdrt2v4o5.onion/wp-includes/js/wp-embed.min.js?ver=4.4.1'\u003e\u003c/script\u003e\n\n\u003c/body\u003e\n\u003c/html\u003e","pageTitle":"Cryptopolitik","responseHeaders":{"CONTENT-TYPE":"text/html; charset=UTF-8","DATE":"Tue, 26 Jul 2016 04:00:26 GMT","LINK":"\u003chttp://35oktenzdrt2v4o5.onion/wp-json/\u003e; rel=\"https://api.w.org/\"","SERVER":"Apache/2.4.10 (Raspbian)","VARY":"Accept-Encoding"},"bitcoinAddresses":null,"sshKey":"","ftpFingerprint":"","ftpBanner":"","smtpFingerprint":"","smtpBanner":""}
